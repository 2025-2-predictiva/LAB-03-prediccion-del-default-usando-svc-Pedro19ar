{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d892d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    balanced_accuracy_score, confusion_matrix\n",
    ")\n",
    "from sklearn.discriminant_analysis import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddf1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos. Tamaños:\n",
      "Entrenamiento: (20953, 24)\n",
      "Prueba: (8979, 24)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets comprimidos\n",
    "train_df = pd.read_csv('../files/input/train_data.csv.zip', compression='zip')\n",
    "test_df  = pd.read_csv('../files/input/test_data.csv.zip',  compression='zip')\n",
    "\n",
    "# Renombrar la columna objetivo\n",
    "train_df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "test_df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "\n",
    "# Eliminar ID y registros nulos\n",
    "train_df.drop(columns=['ID'], inplace=True)\n",
    "test_df.drop(columns=['ID'], inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Normalizar EDUCATION: agrupar valores mayores a 4 como \"otros\"\n",
    "train_df['EDUCATION'] = train_df['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "test_df['EDUCATION']  = test_df['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "# Eliminar registros con EDUCATION=0 o MARRIAGE=0\n",
    "train_df = train_df[(train_df['EDUCATION'] != 0) & (train_df['MARRIAGE'] != 0)]\n",
    "test_df  = test_df[(test_df['EDUCATION'] != 0) & (test_df['MARRIAGE'] != 0)]\n",
    "\n",
    "print(\"Datos listos. Tamaños:\")\n",
    "print(\"Entrenamiento:\", train_df.shape)\n",
    "print(\"Prueba:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1ba11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos creados:\n",
      "X_train: (20953, 23), y_train: (20953,)\n",
      "X_test:  (8979, 23),  y_test:  (8979,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_df.drop(columns=['default']), train_df['default']\n",
    "X_test,  y_test  = test_df.drop(columns=['default']),  test_df['default']\n",
    "\n",
    "print(\"Conjuntos creados:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test:  {X_test.shape},  y_test:  {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89122be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas y numéricas\n",
    "cat_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "num_features = [c for c in X_train.columns if c not in cat_features]\n",
    "\n",
    "# Preprocesamiento\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    (\"cat_encoder\", OneHotEncoder(), cat_features),\n",
    "    (\"num_scaler\", StandardScaler(), num_features)\n",
    "])\n",
    "\n",
    "# Construcción del pipeline completo\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", transformer),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"feature_select\", SelectKBest(f_classif)),\n",
    "    (\"svc_model\", SVC(random_state=12))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec289402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "Mejores hiperparámetros: {'feature_select__k': 12, 'pca__n_components': 20, 'svc_model__gamma': 0.1, 'svc_model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Parámetros para validación cruzada\n",
    "search_params = {\n",
    "    \"pca__n_components\": [20, 21],\n",
    "    \"feature_select__k\": [12],\n",
    "    \"svc_model__kernel\": [\"rbf\"],\n",
    "    \"svc_model__gamma\": [0.1]\n",
    "}\n",
    "\n",
    "# GridSearchCV con validación cruzada de 10 particiones\n",
    "grid = GridSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_grid=search_params,\n",
    "    cv=10,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    refit=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {grid.best_params_}\")\n",
    "best_pipeline = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabe29cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en ../files/models/model.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../files/models\", exist_ok=True)\n",
    "\n",
    "with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as file:\n",
    "    pickle.dump(grid, file)\n",
    "\n",
    "print(\"Modelo guardado en ../files/models/model.pkl.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed825b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>precision</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metrics</td>\n",
       "      <td>train</td>\n",
       "      <td>0.702692</td>\n",
       "      <td>0.664692</td>\n",
       "      <td>0.375661</td>\n",
       "      <td>0.489588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metrics</td>\n",
       "      <td>test</td>\n",
       "      <td>0.673675</td>\n",
       "      <td>0.668100</td>\n",
       "      <td>0.386674</td>\n",
       "      <td>0.491333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type dataset  precision  balanced_accuracy    recall  f1_score\n",
       "0  metrics   train   0.702692           0.664692  0.375661  0.489588\n",
       "1  metrics    test   0.673675           0.668100  0.386674  0.491333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas guardadas en ../files/output/metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "y_pred_train = best_pipeline.predict(X_train)\n",
    "y_pred_test  = best_pipeline.predict(X_test)\n",
    "\n",
    "# Cálculo de métricas\n",
    "os.makedirs(\"../files/output\", exist_ok=True)\n",
    "\n",
    "results = [\n",
    "    {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"precision\": precision_score(y_train, y_pred_train),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_train, y_pred_train),\n",
    "        \"recall\": recall_score(y_train, y_pred_train),\n",
    "        \"f1_score\": f1_score(y_train, y_pred_train),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"precision\": precision_score(y_test, y_pred_test),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred_test),\n",
    "        \"recall\": recall_score(y_test, y_pred_test),\n",
    "        \"f1_score\": f1_score(y_test, y_pred_test),\n",
    "    }\n",
    "]\n",
    "\n",
    "# Mostrar resultados\n",
    "display(pd.DataFrame(results))\n",
    "\n",
    "# Guardar en metrics.json\n",
    "with open(\"../files/output/metrics.json\", \"w\") as file:\n",
    "    for entry in results:\n",
    "        json.dump(entry, file)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Métricas guardadas en ../files/output/metrics.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3622422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión (Entrenamiento):\n",
      " [[15477   751]\n",
      " [ 2950  1775]]\n",
      "Matriz de confusión (Prueba):\n",
      " [[6716  357]\n",
      " [1169  737]]\n"
     ]
    }
   ],
   "source": [
    "# Calcular matrices\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test  = confusion_matrix(y_test,  y_pred_test,  labels=[0, 1])\n",
    "\n",
    "tn_tr, fp_tr, fn_tr, tp_tr = cm_train.ravel()\n",
    "tn_te, fp_te, fn_te, tp_te = cm_test.ravel()\n",
    "\n",
    "conf_results = [\n",
    "    {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"true_0\": {\"predicted_0\": int(tn_tr), \"predicted_1\": int(fp_tr)},\n",
    "        \"true_1\": {\"predicted_0\": int(fn_tr), \"predicted_1\": int(tp_tr)},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"true_0\": {\"predicted_0\": int(tn_te), \"predicted_1\": int(fp_te)},\n",
    "        \"true_1\": {\"predicted_0\": int(fn_te), \"predicted_1\": int(tp_te)},\n",
    "    },\n",
    "]\n",
    "\n",
    "# Guardar matrices en el mismo archivo JSON\n",
    "with open(\"../files/output/metrics.json\", \"a\") as file:\n",
    "    for row in conf_results:\n",
    "        json.dump(row, file)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Matriz de confusión (Entrenamiento):\\n\", cm_train)\n",
    "print(\"Matriz de confusión (Prueba):\\n\", cm_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
